## Isolated word spelling correction using the noisy channel model

![image-20201116130455650](../../../AppData/Roaming/Typora/typora-user-images/image-20201116130455650.png)

- We have an original word
- When user types, it goes through a **Noisy Channel**
- Ends up with a noisy word (**x**)
- Decoder simulates artificial noisy channel
- For each hypothesis word --> words in dictionary, creates a noisy word
- And to find a noisy word that is the most similar to noisy word **x**

## Noisy Channel

- We see an observation x of a misspelled word
- Find the correct word w
- P(A,B) =  P(A|B) P(B)  =  P(B|A) P(A) 

  - P(A,B) = ( P(B|A) P(A) ) / P(B)

$\hat{w} = argmax P(w|x) $

$= argmaxP(x|w)P(w)\over P(x)$ **Bayes Rule**

$\hat{w} = argmax P(x|w)P(w) $

==Probability of possible Correct w = Probability of Generated Noisy word given Hypothesized Word * Probability of Hypothesized Word==

- Look for most likely probability of hypothesized word given that the generated noisy word argmax P(w|x)

- P(x|w) means 

- Example:

  - acress

- Words with similar spelling

  - Small **edit distance** to error

  Words with similar pronunciation
  
  * Small distance of pronunciation to error
    * Soundex Algorithm

## Candidate Testing: Damerau-Levenshtein Edit Distance

- Minimal edit distance between two strings, where edits are:
  - Insertion
  - Deletion
  - Substitution
  - Transposition of two adjacent letters

### Candidate Generation

- %80 of errors are within edit distance 1
- Almost errors are within edit distance 2

- Also allow insertion of **space** or **hyphen**
  - thisidea --> this idea
  - inlaw --> in-law
- Can also allow merging words
  - data base --> database
  - For short text like a query, can just regard whole string as one item from which to produce edits

### What does P(w) means in  $\hat{w} = argmax P(x|w)P(w) $ ?

- (Channel) Error Model $P(w|x) $
- Language Model $P(w)$

### Language Model

- You need a corpus for count the occurrences of the word
- Take a big supply of words (your document collection with *T* tokens); let C(w) = # occurrences of w
  - P(w) = C(w) / T
- In other applications -- you can take the supply to be typed queries (suitably filtered) - when a static dictionary is in adequate

Unigram Prior Probability

### Channel model Probability

- Error model probability, Edit Probability

- Misspelled word x = x~1~, x~2~, x~3~, x~m~
- Correct word w = w~1~, w~2~ , w~3~, w~n~

- P(x|w) = Probability of the edit
  - probability of a error given the correct word
  - (deletion, insertion, substitution, transposition)

- corpus with spelling errors --> you can count the probability of a error each edit operation



### Computing error probability: confusion "matrix"

delete[x,y]:    count(xy typed as x) Error: deletion of y

insert[x,y]:    count(x typed as xy) Error: insertion of y 

- For insertion matrix insert[x, y] **x is insert after y by error**

sub[x,y]:    count(y typed as x) Error: writing x not y

transposition[x,y]:    count(xy typed as yx) 

- x and y characters
- Insertion and deletion conditioned on previous character

<img src="../../../AppData/Roaming/Typora/typora-user-images/image-20201117230106025.png" alt="image-20201117230106025" style="zoom:150%;" />

Smoothing probability: Add-1 smoothing

- But if we use the confusion matrix example, unseen errors are impossible!

  - For example, sub[a,q] = 0 but they are adjacent at the keyboard

- They'll make the overall probability 0. That seems too harsh

- A simple solution is to add 1 to all counts and then if there is a A character alphabet, to normalize appropriately:

  ​			If subs, P(x|w) = sub[x,w]+1 / count[w] + A

  Chanel model for *acress*

![image-20201117223115800](../../../AppData/Roaming/Typora/typora-user-images/image-20201117223115800.png)

## Using context

- "...a stellar and versatile **acrees** whose combination of sass and glamour has defined her..."
- Bigram language model
  - P(actress|versatile) = .000021
    - P()
  - P(across|versatile) = .000021
  - P(whose|actress) = .0010
  - P(whose|actress) = .000006
- P("versatile actress whose") = .000021 * .0010 = 210 * 10^-10^
- P("versatile across whose") = .000021 * .0000006 = 1 * 10^-10^

- Multiplying with channel model, now chooses the word **actress**



Questions:

- Noisy channel modelinde decoder hipotez olarak üretilen kelimeleri noisy chanel a sokuyor ve çıkan noisy wordleri query noisy word ile eşleştiriyor diye not almışım acaba P(w|x) = P(x|w)*P(w) de P(x|w) bu decoder sürecine mi tekabül ediyor?
- Spelling error corpus u verilmeden hatalı query ile edit distance ı 1 olan hipotez kelimeleri nasıl alabiliriz?
- Probability of highest possible Correct w = Probability of Query-given Noisy word "given" Hypothesized Word * Probability of Hypothesized Word olarak 
- insert[x,y]:    count(x typed as xy) Error: insertion of y 
  - For insertion matrix insert[x, y] **x is inserted after y by error**
  - İlk slayttaki notasyonun açıklaması count(y typed as yx) olması gerekmiyor mu?



### Soundex Algorithm - Typical Algorithm

1. Retain the first letter of the word
2. Change all occurrences of the following letters to 0 'zero'
   - A, E, I, O, U, H, W, Y
3. Change letters to digits as follows:
   * B, F, P, V --> 1
   * C, G, J, K, Q, S, X, Z --> 2
   * D, T --> 3 
   * L --> 4
   * M, N --> 5
   * R --> 6
4. Remove all pairs of consecutive digits her Herma55 --> herma5
5. Remove all zeros from the resulting string
6. Pad the resulting string with trailing zeros and return the first four positions, which will be of the form 
   - <uppercase letter> <digit><digit><digit>

- Soundex is the classic algorithm, provided by most databases (Oracle, Microsoft)

### What queries can we process

- We have
  - Positional inverted index with skip pointers
  - Wildcard index
  - Spell-correction
  - Soundex
- Queries such as
  - (SPELL(moriset) |3 tor*to) OR SOUNDEX(chaikofski)

# Term Weighting and the Vector Space Model



## Ranked Retrieval

- Thus far, our queries have **all been Boolean**
  - Documents either match or don't
- Good for expert user with precise understanding of their needs and the collection
  - Also good for applications: Applications can easily consume 1000s of results
- **Not good for the majority of users**
  - Most users incapable of writing Boolean queries (or they are but they think it's too much work)
- Most users don't want to wade through 1000s of results.
  - This particularly true of web search.

#### Problem with Boolean Search: Feast or famine

- Boolean queries often result in either too few (=0) or too many (1000s) results.
  - Query 1 [Boolean Conjunction]:
    - "justin bieber istanbul konseri" --> 283,000 hits
  - Query 1 [Boolean Conjunction]:
    - "justin bieber istanbul konseri yeri" --> 0 hits

- It takes a lot of skill to come up with a query that produces a manageable number of hits
  - In general: **AND gives too few; OR give too many**

### Ranked Retrieval Models

- Rather than a set of documents satisfying a query expression, in ranked retrieval models, the system returns an ordering over the (top) documents in the collection with respect to a query
- **Free text queries**: Rather than a query language of operators and expressions, the user's query is just one or more words in a human language
- In principle, there are two separate choices here, but in practice, ranked retrieval models have normally been associated with free text queries and vice versa

- When a system produces a ranked result set **large result sets are not an issue**
  - Indeed, the size of the result set is not an issue
  - We just show the top k (&asymp; 10) results 
  - We don't overwhelm the user
- - **Premise: the ranking algorithm works**

#### Importance of Ranking

- Viewing abstracts: Users are a lot more likely to reas the abstracts of the top-ranked pages than the abstracts of the lower ranked pages
- Clicking: Distribution is even more skewed for clicking
- In 1 out of 2 cases, users click on the top-ranked page.
- Even if the top ranked page is not relevant, 30% of users will click on it

- **Getting the ranking right is very important**
- **Getting the top ranked page right is most important**

#### Scoring as the basis of ranked retrieval

- We wish to return in order the documents most likely to be useful to the searcher
- **How can we rank-order the documents in the collection with respect to a query?**
- Assign a score -- say in [0,1] -- to each document
- **This score measures how well document and query "match"**

#### Query-document matching scores

- We need a way of assigning a score to a query/document pair
- Let's start with a one-term query
- If the query term does not occur in the document:
  - Score --> 0
- **The more frequent the query term in the document, the higher the score** (should be)

### Jaccard Coefficient

- A commonly used measure of overlap of two sets A and B
- jaccard(A,B) = |A &cap; B| / |A &cup; B|
- jaccard(A,A) = 1
- jaccard(A,B) = 0 if A &cap; B = 0
- A and B don't have to be the same size
- Always assigns a number between 0 and 1.

Scoring Example

- What is the query-document match score that the Jaccard coefficient computes for each of the two document:
  - Query: ides of march
  - Document 1: caesar died in march 1/6
    - Document 2: of the long march 2/5

Issues with Jaccard for scoring

- "of" has the same affect as "march"
  - "of" is very frequent --> therefore less score

- But March has multiple use
  - td-idf cannot resolve
  - word sense disambiguation --> NLP area
- It doesn't consider **term frequency** (how many times a term occurs in a document)
- Rare terms in a collection are more informative than frequent terms. Jaccard doesn't consider this information



- **Binary vectors --> Each document that a word occurs is a binary vector in Binary term-document incidence matrix**
  - document = binary vector  if the word is in the document
  - One with a sparse matrix

- Count vectors --> Each document noun (token) is a count vector
  - Dimensionality of the vector is the size of the vocabulary

## Bag of Words Model

- Vector representation doesn't consider the ordering of words in a document
- *John is quicker than Mary* and *Mary is quicker than John* have the same vector
  - vocabulary is the same
  - word order different
- This is called the **bag of words** model